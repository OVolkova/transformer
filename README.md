# transformer
Transformer Neural Networks architecture implementation

# TODO: split dataset into batches with similar lengths
# TODO: check vocab size, max length, etc.
# TODO: check BPE algorithms.
# TODO: optimizer, scheduler, loss function, etc.
# TODO: training loop with metrics and logging
# TODO: inference loop with metrics and logging
# TODO: Attention Visualization
# TODO: train on usual datasets model was initially trained on
# TODO: train on selected fun dataset code-to-text
